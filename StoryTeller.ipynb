{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text using Markov Chains\n",
    "\n",
    "### Aim:\n",
    "In this notebook, we aim to generate similar storyline like Harry Potter by building a 1st Order Markov Chains around all the books of Harry Potter at word level. To know in detail the working of the model read the related blog [here](https://medium.com/@prakhar.mishra/can-bots-tell-you-stories-357a77bef4c9).\n",
    "\n",
    "### Author:\n",
    "1. [Prakhar Mishra](https://www.linkedin.com/in/prakhar21/)\n",
    "\n",
    "__For more such materials follow me on __[Medium](https://medium.com/@prakhar.mishra)\n",
    "\n",
    "### Resources:\n",
    "1. [Markov Chain explained Visually](http://setosa.io/ev/markov-chains/)\n",
    "2. [Markov Chains in Python](https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial)\n",
    "3. [Markov Chains (YouTube)](https://www.youtube.com/watch?v=uvYTGEZQTEs)\n",
    "\n",
    "### Improvement Scope\n",
    "1. Try higher order markov chains (maybe 2 or 3)\n",
    "2. Try increasing vocabulary of words in the current one.\n",
    "3. Try tuning the exploration factor i.e. randomness_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import operator\n",
    "import codecs\n",
    "import random\n",
    "import nltk\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class that encapsulates all the functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(object):\n",
    "    \n",
    "    def __init__(self, data_list):\n",
    "        self.text = self._load(data_list)\n",
    "        self.text_tokens = self._prune(self._tokenize())\n",
    "        self.states = list(set(self.text_tokens))\n",
    "        self.possible_transitions = self._get_transitions()\n",
    "        self.trasnsition_probabilites = self.train()\n",
    "        self.total_words = 0.0\n",
    "        \n",
    "    def _load(self, files):\n",
    "        text = \" \"\n",
    "        for f in files:\n",
    "            print('Reading {}'.format(f))\n",
    "            with codecs.open(f, 'rb', 'utf-8') as infile:\n",
    "                text += self._clean(infile.read().encode('utf-8').decode('ascii', 'ignore')).strip()\n",
    "        return text\n",
    "    \n",
    "    def _get_possibilities(self, state):\n",
    "        words = []\n",
    "        for index, value in enumerate(self.text_tokens):\n",
    "            if value == state:\n",
    "                try:\n",
    "                    words.append(self.text_tokens[index+1])\n",
    "                except:\n",
    "                    words.append('EOS')\n",
    "        return {state: dict(collections.Counter(words))}\n",
    "    \n",
    "    def _add_probabilities(self, possibilities):\n",
    "        temp = {}\n",
    "        for possibility in possibilities:\n",
    "            for k, v in possibility.items():\n",
    "                temp[k] = [{'probab': (count/float(self.total_words)) * (1/float(len(v))), 'word': wrd} for wrd,count in v.items()]\n",
    "        return temp\n",
    "    \n",
    "    def train(self):\n",
    "        possibilities = []\n",
    "        for state in self.states:\n",
    "            possibilities.append(self._get_possibilities(state))\n",
    "        probabilities = self._add_probabilities(possibilities)\n",
    "        return probabilities\n",
    "            \n",
    "    def _get_transitions(self):\n",
    "        return [[self.states] for state in self.states]\n",
    "    \n",
    "    def _prune(self, tokens):\n",
    "        if len(tokens) > 100000:\n",
    "            self.total_words = 100000\n",
    "            return tokens[:self.total_words]\n",
    "        self.total_words = len(tokens)\n",
    "        return tokens\n",
    "        \n",
    "    def _clean(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"(\\n|\\t|/)\", \" \", text)\n",
    "        text = re.sub(r'([.,/#!$%^&*;:{}=_`~()-])[.,/#!$%^&*;:{}=_`~()-]+', r'\\1', text)\n",
    "        text = re.sub('([.,!?()])', r' \\1 ', text)\n",
    "        return re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    def get_len(self, d):\n",
    "        return len(d)\n",
    "    \n",
    "    def _tokenize(self):\n",
    "        tokens = nltk.word_tokenize(self.text)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Calculating Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Agatha_Cristie-1939_diez_negritos.txt\n",
      "Length of the training file 290204\n",
      "Number of words 56663\n",
      "['recurrio', 'sombrio', 'pasar', 'acostada', 'soldados', 'campana', 'confusa', 'enganaran', 'necesario', 'sabor', 'hacha', 'sonrio', 'cazar', 'encargos', 'exposicion']\n"
     ]
    }
   ],
   "source": [
    "# preparing the data for training the model\n",
    "\n",
    "files = ['Agatha_Cristie-1939_diez_negritos.txt']\n",
    "\n",
    "generator = TextGenerator(files)\n",
    "\n",
    "# length of the text\n",
    "print(\"Length of the training file {}\".format(generator.get_len(generator.text)))\n",
    "print(\"Number of words {}\".format(generator.get_len(generator.text_tokens)))\n",
    "print(generator.states[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Story using the patterns observed from Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony contesto . no se lo he ahi ? pregunto : el juez , que no se dirigio al cabo la casa y la cabeza . no , que le habia visto una isla del comedor , y se dirigio a los demas de su mujer , y el juez , pero no , pero el juez wargrave se dirigio a los demas a la isla del negro ! el doctor . no es el juez wargrave se dirigio a los dos hombres . la casa y la isla . no es la cabeza , y se dirigio al doctor\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "def formatter(s):\n",
    "    s = s.split()\n",
    "    # greedy sentence finisher (matches to last (.))\n",
    "    s = ' '.join(s[:[idx for idx, ch in enumerate(s) if ch == '.'][-1]+1])\n",
    "    s = s.capitalize()  # sentence casing\n",
    "    s = re.sub(r'\\s(\\.|,|!|\\?|\\(|\\)|\\]|\\[)', r'\\1', s) # remove padded space before punc.\n",
    "    return s\n",
    "\n",
    "# palabra inicial\n",
    "seed_word = 'tony'\n",
    "story = [seed_word]\n",
    "words = 0\n",
    "max_words = 100\n",
    "randomness_level = 3\n",
    "\n",
    "while words < max_words-1:\n",
    "    words += 1    \n",
    "    candidates = generator.trasnsition_probabilites.get(seed_word)\n",
    "    if candidates:\n",
    "        temp = sorted(candidates, key=lambda c: c['probab'], reverse=True)\n",
    "        candidates = [i.get('probab') for i in temp]\n",
    "        grouped = sum([i[1] for i in [(k, sum(1 for i in g)) \n",
    "                                      for k,g in itertools.groupby(candidates)][:randomness_level]])\n",
    "        seed_word = random.choice(temp[:grouped]).get('word')\n",
    "        story.append(seed_word)\n",
    "\n",
    "print(' '.join(story))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después sólo dirían: «El viejo MacArthur no era cándido; el fastidio con los ladrillos. —¿Y ha estado demasiado... lejos. —¿Qué demonios insinúa usted, doctor?\n",
      "¿qué cosa más rara!\n",
      "La señora Rogers fueron los primeros en llegar a la vida es cada vez más peligrosa.\n",
      "Ya calmado, dijo en voz baja. —Precisamente.\n",
      "Otras eventualidades se presentaban a su cuarto siempre lee la Biblia.\n",
      "¡Buena idea habían tenido jamás miedo.\n",
      "Me pregunto lo que importa es examinar el tercer crimen y establecer el hecho de que no le satisfacía sino a medias...\n",
      "Apoyada en los caracteres de los acusados eran culpables de los peldaños se encontraron sobre una mesa.\n"
     ]
    }
   ],
   "source": [
    "# Get raw text as string.\n",
    "with open('Agatha_Cristie-1939_diez_negritos.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 140 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
